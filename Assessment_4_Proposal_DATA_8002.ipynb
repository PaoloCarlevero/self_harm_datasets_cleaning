{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utqvj4I4hmR1"
      },
      "source": [
        "# **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q zipfile36 contractions"
      ],
      "metadata": {
        "id": "-zrEjlBkfIon"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "q2miP8u7hfsP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import re\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "\n",
        "import contractions\n",
        "import kagglehub\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and load NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk_stopwords = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecH__OdCzuba",
        "outputId": "bb06ed87-9107-4f3b-b045-c465c1854bdf"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load spaCy English model\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "hUWma7vu3pQR"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set styles\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_context(\"talk\")"
      ],
      "metadata": {
        "id": "uZ-d4nZVzRhQ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkWknl5WdDYD"
      },
      "source": [
        "# **Importing datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV0K-rTUz3x3"
      },
      "source": [
        "## mental_health"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "hnJg9kkBsF1J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "10f6b0b4-50a1-465b-f108-1b91d77084d4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-27e51c200b11>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"szegeelim/mental-health\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmental_health\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/Combined Data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/datasets.py\u001b[0m in \u001b[0;36mdataset_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_dataset_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading Dataset: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mfails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/colab_cache_resolver.py\u001b[0m in \u001b[0;36mis_supported\u001b[0;34m(self, handle, *_, **__)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColabClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIS_DATASET_SUPPORTED_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, data, handle_path, resource_handle)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_handle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mResourceHandle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"http://{self.endpoint}{handle_path}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         with requests.post(\n\u001b[0m\u001b[1;32m    420\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"szegeelim/mental-health\")\n",
        "mental_health = pd.read_csv(path + \"/Combined Data.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AfAcov3z0hP"
      },
      "source": [
        "## suicidal_tweet_detection_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"aunanya875/suicidal-tweet-detection-dataset\")\n",
        "suicidal_tweet_detection_dataset = pd.read_csv(path + \"/Suicide_Ideation_Dataset(Twitter-based).csv\")"
      ],
      "metadata": {
        "id": "t_k8Xkm5-gtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAGyc9OOzxWp"
      },
      "source": [
        "## reddit_mental_health_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset\n",
        "path = kagglehub.dataset_download(\"neelghoshal/reddit-mental-health-data\")\n",
        "reddit_mental_health_data = pd.read_csv(path + \"/data_to_be_cleansed.csv\", index_col=0)\n",
        "\n",
        "# Decode target variable\n",
        "mental_health_target_map = {\n",
        "    0: \"Stress\",\n",
        "    1: \"Depression\",\n",
        "    2: \"Bipolar disorder\",\n",
        "    3: \"Personality disorder\",\n",
        "    4: \"Anxiety\"\n",
        "}\n",
        "\n",
        "reddit_mental_health_data[\"target\"] = reddit_mental_health_data[\"target\"].map(mental_health_target_map)"
      ],
      "metadata": {
        "id": "lsCw5Pge_moA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dreaddit"
      ],
      "metadata": {
        "id": "2hPGWtFfeZTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o ./dreaddit.zip \"http://www.cs.columbia.edu/~eturcan/data/dreaddit.zip\""
      ],
      "metadata": {
        "id": "ibcoqk6hBSmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concat CSV\n",
        "with zipfile.ZipFile(\"dreaddit.zip\") as z:\n",
        "\n",
        "   with z.open(\"dreaddit-train.csv\") as f:\n",
        "      dreaddit_train = pd.read_csv(f)\n",
        "\n",
        "   with z.open(\"dreaddit-test.csv\") as f:\n",
        "      dreaddit_test = pd.read_csv(f)\n",
        "\n",
        "# Select training dataset\n",
        "dreaddit = dreaddit_train\n",
        "\n",
        "# Decode target variable\n",
        "dreaddit['label'] = dreaddit['label'].map({0: 'Not stressful', 1: 'Stressful'})"
      ],
      "metadata": {
        "id": "J6_qkKQ-faa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZHR3cuht3IA"
      },
      "source": [
        "# **Descriptive analysis - Raw**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s82rYlAt549"
      },
      "source": [
        "## mental_health"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Akd_a6mYuRNs"
      },
      "outputs": [],
      "source": [
        "mental_health.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq5Qt8zJuCmJ"
      },
      "outputs": [],
      "source": [
        "mental_health.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0CXgFR4updU"
      },
      "source": [
        "## suicidal_tweet_detection_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyQAnjyDuqzy"
      },
      "outputs": [],
      "source": [
        "suicidal_tweet_detection_dataset.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXLpUAZoxLGs"
      },
      "outputs": [],
      "source": [
        "suicidal_tweet_detection_dataset.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpPJJSsaxwM5"
      },
      "source": [
        "## reddit_mental_health_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWUGtiePx4AO"
      },
      "outputs": [],
      "source": [
        "reddit_mental_health_data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X703kKh7xvnS"
      },
      "outputs": [],
      "source": [
        "reddit_mental_health_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dreaddit"
      ],
      "metadata": {
        "id": "aAN_2r9bhRuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dreaddit.dtypes"
      ],
      "metadata": {
        "id": "ewSNNic9hR4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dreaddit.describe()"
      ],
      "metadata": {
        "id": "TuNbljzghR-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dreaddit.describe(include='object')"
      ],
      "metadata": {
        "id": "LSYuWWRMi34Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I74crXQetB7p"
      },
      "source": [
        "# **Data quality - Raw**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pTXUsLWtLfX"
      },
      "source": [
        "## mental_health"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJwybWghjMHc"
      },
      "outputs": [],
      "source": [
        "mental_health.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGg9oy9BlXIq"
      },
      "outputs": [],
      "source": [
        "mental_health[mental_health['statement'].isna()]['status'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaT_fiGJvs5c"
      },
      "source": [
        "## suicidal_tweet_detection_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7N5Ak32vuSI"
      },
      "outputs": [],
      "source": [
        "suicidal_tweet_detection_dataset.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtMhZIvI1u5m"
      },
      "source": [
        "## reddit_mental_health_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYhv_h2p10BQ"
      },
      "outputs": [],
      "source": [
        "mental_health.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Dreaddit"
      ],
      "metadata": {
        "id": "RRfr53SZhhhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dreaddit_na = dreaddit.isna().sum()\n",
        "\n",
        "dreaddit_na.loc[dreaddit_na > 0]"
      ],
      "metadata": {
        "id": "pzs2wwobiZVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edEf6VjGtRBB"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCZtw1Nktbcx"
      },
      "source": [
        "## mental_health"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNTMeB3ytf47"
      },
      "outputs": [],
      "source": [
        "# Delete rows with missing statement\n",
        "mental_health = mental_health.dropna()\n",
        "\n",
        "# Drop statement's dupicates\n",
        "mental_health = mental_health.drop_duplicates(subset='statement')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8gjDgMRwEo3"
      },
      "source": [
        "## suicidal_tweet_detection_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gauweztKwGFr"
      },
      "outputs": [],
      "source": [
        "# Delete rows with missing Tweet\n",
        "suicidal_tweet_detection_dataset = suicidal_tweet_detection_dataset.dropna()\n",
        "\n",
        "# Drop tweet's dupicates\n",
        "suicidal_tweet_detection_dataset = suicidal_tweet_detection_dataset.drop_duplicates(subset='Tweet')\n",
        "\n",
        "# Add column with name of the social where the text was posted\n",
        "suicidal_tweet_detection_dataset['social'] = 'Twitter'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChtET-GC2koR"
      },
      "source": [
        "## reddit_mental_health_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67XgDcWM2isB"
      },
      "outputs": [],
      "source": [
        "# Delete rows with missing Tweet\n",
        "reddit_mental_health_data = reddit_mental_health_data.dropna()\n",
        "\n",
        "# Drop tweet's dupicates\n",
        "reddit_mental_health_data = reddit_mental_health_data.drop_duplicates(subset='text')\n",
        "\n",
        "# Add column with name of the social where the text was posted\n",
        "reddit_mental_health_data['social'] = 'Reddit'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dreaddit"
      ],
      "metadata": {
        "id": "yKigDcOljQKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where text in missing\n",
        "dreaddit = dreaddit.loc[dreaddit['text'] != '#NAME?']\n",
        "\n",
        "# Drop dupicates\n",
        "dreaddit = dreaddit.drop_duplicates(subset=['subreddit', 'text'])\n",
        "\n",
        "# Add column with name of the social where the text was posted\n",
        "dreaddit['social'] = 'Reddit'"
      ],
      "metadata": {
        "id": "9VUAZu0ZjR7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca8hQO3XwdpG"
      },
      "source": [
        "# **Descriptive analysis - Preprocessed**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9dxuFR4w8ym"
      },
      "source": [
        "## mental_health"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrKbnZNei7Zh"
      },
      "outputs": [],
      "source": [
        "mental_health.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## suicidal_tweet_deterction_dataset"
      ],
      "metadata": {
        "id": "YQvN78WXXspv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mental_health.describe()"
      ],
      "metadata": {
        "id": "KIr-xPJRXsCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reddit_mental_health_data"
      ],
      "metadata": {
        "id": "3X6npzu_YmsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_mental_health_data.describe()"
      ],
      "metadata": {
        "id": "RKMSd5faYpdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dreaddit"
      ],
      "metadata": {
        "id": "eUy0WQwKkGez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dreaddit.columns"
      ],
      "metadata": {
        "id": "P1uFXZAhk5bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dreaddit.describe()"
      ],
      "metadata": {
        "id": "sDM8YMUjkIEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dreaddit.describe(include='object')"
      ],
      "metadata": {
        "id": "uTM4DvESkIJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo7faL6otVtB"
      },
      "source": [
        "# **Data quality - Preprocessed**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vcjydsz3tnM4"
      },
      "source": [
        "## mental_health"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSBnz0e9lTHM"
      },
      "outputs": [],
      "source": [
        "mental_health.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZ3yWchEjjwP"
      },
      "outputs": [],
      "source": [
        "mental_health['status'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## suicidal_tweet_detection_dataset"
      ],
      "metadata": {
        "id": "Ay_4HIuWX70S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "suicidal_tweet_detection_dataset.isna().sum()"
      ],
      "metadata": {
        "id": "G6nDMZkbY3K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suicidal_tweet_detection_dataset['Suicide'].value_counts()"
      ],
      "metadata": {
        "id": "RSfz1igPY3N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reddit_mental_health_data"
      ],
      "metadata": {
        "id": "ZFek1HDzYSj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_mental_health_data.isna().sum()"
      ],
      "metadata": {
        "id": "-Z4hKEHjY07U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_mental_health_data['target'].value_counts()"
      ],
      "metadata": {
        "id": "uDopqQeUX7O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature engineering**"
      ],
      "metadata": {
        "id": "JqjSZpH3zJAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mental_health"
      ],
      "metadata": {
        "id": "sXQPC_8wzcfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add text length feature (word count)\n",
        "mental_health['text_length'] = mental_health['statement'].apply(lambda x: len(str(x).split()))"
      ],
      "metadata": {
        "id": "KNCNLOyIzb9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean statement\n",
        "def preprocess(text):\n",
        "    \"\"\"Lowercase, remove non-alpha chars, strip stopwords.\"\"\"\n",
        "    if isinstance(text, str):\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
        "        words = text.strip().split()\n",
        "        meaningful_words = [word for word in words if word not in nltk_stopwords]\n",
        "        return ' '.join(meaningful_words)\n",
        "    return \"\"\n",
        "\n",
        "mental_health['clean_statement'] = mental_health['statement'].apply(preprocess)"
      ],
      "metadata": {
        "id": "lUruzun1zpAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## suicidal_tweet_detection_dataset"
      ],
      "metadata": {
        "id": "ysHza_gX0tGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate text length\n",
        "suicidal_tweet_detection_dataset['text_length'] = suicidal_tweet_detection_dataset['Tweet'].apply(lambda x: len(str(x).split()))"
      ],
      "metadata": {
        "id": "ATV50Aie0sPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reddit_mental_health_data"
      ],
      "metadata": {
        "id": "NCf9olnX2Rrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate text length\n",
        "reddit_mental_health_data['text_length'] = reddit_mental_health_data['text'].apply(lambda x: len(str(x).split()))"
      ],
      "metadata": {
        "id": "muzovnR72Qe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dreaddit"
      ],
      "metadata": {
        "id": "T_WBO6J32qU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add text length feature (word count)\n",
        "dreaddit['text_length'] = dreaddit['text'].apply(lambda x: len(str(x).split()))"
      ],
      "metadata": {
        "id": "8bK47BS32-rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map categorical stress label to numeric\n",
        "dreaddit['label_num'] = dreaddit['label'].map({'Not stressful': 0, 'Stressful': 1})"
      ],
      "metadata": {
        "id": "59ir1GW12qjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z93LnXnHoviP"
      },
      "source": [
        "# **Data visualization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QGbSTfwrSbB"
      },
      "source": [
        "## mental_health"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAJbsFEqna1A"
      },
      "outputs": [],
      "source": [
        "# Plot a frequency plot of the status associated to the tweet\n",
        "sns.countplot(data=mental_health,\n",
        "              y='status',\n",
        "              order=mental_health['status'].value_counts().index)\n",
        "\n",
        "plt.title(\"Mental health discorder frequency in mental_health\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create figure and axis for better layout control\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Define the unique number of statuses\n",
        "unique_statuses = mental_health['status'].nunique()\n",
        "\n",
        "# Plot the distribution of mental health conditions by post count\n",
        "sns.countplot(\n",
        "    data=mental_health,\n",
        "    y='status',\n",
        "    hue='status',\n",
        "    order=mental_health['status'].value_counts().index,\n",
        "    legend=False,\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# Add a descriptive title and axis labels for clarity\n",
        "ax.set_title(\"Frequency of Mental Health Conditions in Dataset\", fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel(\"Number of Posts\", fontsize=14)\n",
        "ax.set_ylabel(\"Mental Health Condition\", fontsize=14)\n",
        "\n",
        "# Adjust tick label sizes to improve readability\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "# Remove top and right spines for a cleaner look\n",
        "sns.despine(ax=ax)\n",
        "\n",
        "# Adjust layout and make space at the bottom for the caption\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(bottom=0.2)\n",
        "\n",
        "# Add figure number and caption below the plot\n",
        "fig.text(\n",
        "    0.5, 0.02,\n",
        "    'Figure 6.1.2',\n",
        "    fontsize=12,\n",
        "    fontstyle='italic',\n",
        "    ha='center'\n",
        ")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-jpcUrBhN-Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate 95th percentile threshold\n",
        "percentile_95 = mental_health['text_length'].quantile(0.95)\n",
        "\n",
        "# Filter data below the 95th percentile\n",
        "filtered_data = mental_health[mental_health['text_length'] <= percentile_95]\n",
        "\n",
        "# Calculate summary stats on filtered data\n",
        "mean_length = filtered_data['text_length'].mean()\n",
        "median_length = filtered_data['text_length'].median()\n",
        "max_length = filtered_data['text_length'].max()\n",
        "min_length = filtered_data['text_length'].min()\n",
        "\n",
        "# Create figure and axis for better layout control\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "# Plot histogram on filtered data\n",
        "sns.histplot(\n",
        "    data=filtered_data,\n",
        "    x='text_length',\n",
        "    bins=50,\n",
        "    kde=True,\n",
        "    color='#4C72B0',\n",
        "    edgecolor='white',\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# Style the KDE line\n",
        "plt.setp(ax.lines, linewidth=2, color='#333F4B')\n",
        "\n",
        "# Add mean and median vertical lines\n",
        "ax.axvline(mean_length, color='#FF5733', linestyle='--', linewidth=2, label=f'Mean: {mean_length:.0f} words')\n",
        "ax.axvline(median_length, color='#28B463', linestyle='-.', linewidth=2, label=f'Median: {median_length:.0f} words')\n",
        "\n",
        "# Add title and labels\n",
        "ax.set_title('Distribution of Statement Lengths (Filtered at 95th Percentile)', fontsize=18, fontweight='bold', pad=15)\n",
        "ax.set_xlabel('Number of Words', fontsize=14, labelpad=10)\n",
        "ax.set_ylabel('Frequency', fontsize=14, labelpad=10)\n",
        "\n",
        "# Legend configuration\n",
        "ax.legend(frameon=False, fontsize=12, loc='upper right', bbox_to_anchor=(0.95, 0.95))\n",
        "\n",
        "# Tick label size adjustments\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "# Remove top and right spines for a cleaner look\n",
        "sns.despine(ax=ax)\n",
        "\n",
        "# Add summary stats box inside the figure\n",
        "fig.text(\n",
        "    0.75, 0.5,\n",
        "    f'''\n",
        "Min: {min_length:.0f}\n",
        "Median: {median_length:.0f}\n",
        "Mean: {mean_length:.0f}\n",
        "Max: {max_length:.0f}\n",
        "''',\n",
        "    fontsize=12,\n",
        "    bbox=dict(facecolor='white', edgecolor='gray', boxstyle='round,pad=0.5')\n",
        ")\n",
        "\n",
        "# Adjust layout to leave space for the figure caption\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(bottom=0.2)\n",
        "\n",
        "# Add figure caption below the plot\n",
        "fig.text(\n",
        "    0.5, 0.02,\n",
        "    'Figure 6.1.3',\n",
        "    fontsize=12,\n",
        "    fontstyle='italic',\n",
        "    ha='center'\n",
        ")\n",
        "\n",
        "# Set x axis lower limit\n",
        "plt.xlim(0)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "80BrrAlMNOLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate and display word clouds\n",
        "def generate_wordcloud(text, title, colormap='viridis'):\n",
        "    wordcloud = WordCloud(\n",
        "        width=800,\n",
        "        height=400,\n",
        "        background_color='white',\n",
        "        colormap=colormap,\n",
        "        max_words=100\n",
        "    ).generate(text)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(title, fontsize=16, fontweight='bold')\n",
        "    plt.show()\n",
        "\n",
        "# Loop through each unique status and generate a word cloud\n",
        "for status in mental_health['status'].unique():\n",
        "    # Join all clean statements for this condition\n",
        "    text = ' '.join(mental_health[mental_health['status'] == status]['clean_statement'])\n",
        "\n",
        "    # Generate the word cloud\n",
        "    generate_wordcloud(text, f\"Most Common Words in '{status}' Posts\", colormap='coolwarm')\n"
      ],
      "metadata": {
        "id": "iuhAwonqagMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK5nMxIvrZ8j"
      },
      "source": [
        "## suicidal_tweet_detection_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qGrO4ikj0eu"
      },
      "outputs": [],
      "source": [
        "# Plot a frequency plot of the status associated to the tweet\n",
        "sns.countplot(data=suicidal_tweet_detection_dataset,\n",
        "              y='Suicide',\n",
        "              order=suicidal_tweet_detection_dataset['Suicide'].value_counts().index\n",
        "            )\n",
        "# Set title\n",
        "plt.title(\"Suicide frequency in suicidal_tweet_detection_dataset\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get counts of each class\n",
        "suicide_counts = suicidal_tweet_detection_dataset['Suicide'].value_counts()\n",
        "\n",
        "# Convert to a DataFrame for better readability\n",
        "suicide_counts_df = suicide_counts.reset_index()\n",
        "suicide_counts_df.columns = ['Suicide Status', 'Count']\n",
        "\n",
        "print(suicide_counts_df)"
      ],
      "metadata": {
        "id": "ydg36Xdyz27M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create figure and axis for better layout control\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Define the unique number of statuses\n",
        "unique_statuses = suicidal_tweet_detection_dataset['Suicide'].nunique()\n",
        "\n",
        "# Plot the distribution of mental health conditions by post count\n",
        "sns.countplot(\n",
        "    data=suicidal_tweet_detection_dataset,\n",
        "    y='Suicide',\n",
        "    hue='Suicide',\n",
        "    order=suicidal_tweet_detection_dataset['Suicide'].value_counts().index,\n",
        "    legend=False,\n",
        "    ax=ax  # Pass the axis to sns.countplot\n",
        ")\n",
        "\n",
        "# Add a descriptive title and axis labels for clarity\n",
        "ax.set_title(\"Frequency of Suicide Flag in Dataset\", fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel(\"Number of Posts\", fontsize=14)\n",
        "ax.set_ylabel(\"Suicide Flag\", fontsize=14)\n",
        "\n",
        "# Adjust tick label sizes to improve readability\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "# Remove top and right spines for a cleaner look\n",
        "sns.despine(ax=ax)\n",
        "\n",
        "# Adjust layout and make space at the bottom for the caption\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(bottom=0.2)\n",
        "\n",
        "# Add figure number and caption below the plot\n",
        "fig.text(\n",
        "    0.5, 0.02,\n",
        "    'Figure 6.2.2',\n",
        "    fontsize=12,\n",
        "    fontstyle='italic',\n",
        "    ha='center'\n",
        ")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YejSDn6tujXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate 95th percentile threshold\n",
        "percentile_95 = suicidal_tweet_detection_dataset['text_length'].quantile(0.95)\n",
        "\n",
        "# Filter data below the 95th percentile to reduce skew from outliers\n",
        "filtered_data = suicidal_tweet_detection_dataset[suicidal_tweet_detection_dataset['text_length'] <= percentile_95]\n",
        "\n",
        "# Calculate summary statistics on filtered data\n",
        "mean_length = filtered_data['text_length'].mean()\n",
        "median_length = filtered_data['text_length'].median()\n",
        "max_length = filtered_data['text_length'].max()\n",
        "min_length = filtered_data['text_length'].min()\n",
        "\n",
        "# Create figure and axis for better layout control\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "# Plot histogram on filtered data\n",
        "sns.histplot(\n",
        "    data=filtered_data,\n",
        "    x='text_length',\n",
        "    bins=50,\n",
        "    kde=True,\n",
        "    color='#4C72B0',\n",
        "    edgecolor='white',\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# Style the KDE line for better visibility\n",
        "plt.setp(ax.lines, linewidth=2, color='#333F4B')\n",
        "\n",
        "# Add mean and median vertical lines\n",
        "ax.axvline(mean_length, color='#FF5733', linestyle='--', linewidth=2, label=f'Mean: {mean_length:.0f} words')\n",
        "ax.axvline(median_length, color='#28B463', linestyle='-.', linewidth=2, label=f'Median: {median_length:.0f} words')\n",
        "\n",
        "# Add title and axis labels\n",
        "ax.set_title('Distribution of Tweet Lengths (Filtered at 95th Percentile)', fontsize=18, fontweight='bold', pad=15)\n",
        "ax.set_xlabel('Number of Words', fontsize=14, labelpad=10)\n",
        "ax.set_ylabel('Frequency', fontsize=14, labelpad=10)\n",
        "\n",
        "# Configure legend\n",
        "ax.legend(frameon=False, fontsize=12, loc='upper right', bbox_to_anchor=(0.95, 0.95))\n",
        "\n",
        "# Adjust tick label sizes for readability\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "# Remove spines for a cleaner appearance\n",
        "sns.despine(ax=ax)\n",
        "\n",
        "# Add summary stats box inside the figure\n",
        "fig.text(\n",
        "    0.75, 0.5,\n",
        "    f'''\n",
        "Min: {min_length:.0f}\n",
        "Median: {median_length:.0f}\n",
        "Mean: {mean_length:.0f}\n",
        "Max: {max_length:.0f}\n",
        "''',\n",
        "    fontsize=12,\n",
        "    bbox=dict(facecolor='white', edgecolor='gray', boxstyle='round,pad=0.5')\n",
        ")\n",
        "\n",
        "# Adjust layout and leave space at the bottom for a caption\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(bottom=0.2)\n",
        "\n",
        "# Add figure caption below the plot\n",
        "fig.text(\n",
        "    0.5, 0.02,\n",
        "    'Figure 6.2.3',\n",
        "    fontsize=12,\n",
        "    fontstyle='italic',\n",
        "    ha='center'\n",
        ")\n",
        "\n",
        "# Set x axis lower limit\n",
        "plt.xlim(0)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0sl3VFJYUhor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tokenize_spacy(text):\n",
        "    \"\"\"Expand contractions, lowercase, tokenize, and retain alphabetic tokens (including expanded ones).\"\"\"\n",
        "    if isinstance(text, str):\n",
        "        expanded_text = contractions.fix(text)\n",
        "        doc = nlp(expanded_text.lower())\n",
        "        tokens = [token.text for token in doc if not token.is_punct and not token.is_space]\n",
        "        return tokens\n",
        "    return []\n",
        "\n",
        "def get_top_ngrams(tweets, ngram_range=2, top_n=20):\n",
        "    \"\"\"Extract top n-grams from a list of tweets.\"\"\"\n",
        "    ngram_list = []\n",
        "\n",
        "    for tweet in tweets:\n",
        "        tokens = clean_tokenize_spacy(tweet)\n",
        "        if len(tokens) >= ngram_range:\n",
        "            ngrams = zip(*[tokens[i:] for i in range(ngram_range)])\n",
        "            ngram_list.extend([' '.join(gram) for gram in ngrams])\n",
        "\n",
        "    ngram_counts = Counter(ngram_list)\n",
        "    return ngram_counts.most_common(top_n)\n",
        "\n",
        "# Strip whitespace from 'Suicide' column values\n",
        "suicidal_tweet_detection_dataset['Suicide'] = suicidal_tweet_detection_dataset['Suicide'].str.strip()\n",
        "\n",
        "# Filter suicidal and non-suicidal tweets\n",
        "suicidal_tweets = suicidal_tweet_detection_dataset[\n",
        "    suicidal_tweet_detection_dataset['Suicide'] == 'Potential Suicide post'\n",
        "]['Tweet']\n",
        "\n",
        "non_suicidal_tweets = suicidal_tweet_detection_dataset[\n",
        "    suicidal_tweet_detection_dataset['Suicide'] == 'Not Suicide post'\n",
        "]['Tweet']\n",
        "\n",
        "# Get top bigrams for each class\n",
        "top_bigrams_suicidal = get_top_ngrams(suicidal_tweets, ngram_range=2, top_n=20)\n",
        "top_bigrams_non_suicidal = get_top_ngrams(non_suicidal_tweets, ngram_range=2, top_n=20)\n",
        "\n",
        "print(\"Top Bigrams in Suicidal Tweets:\")\n",
        "print(top_bigrams_suicidal)\n",
        "\n",
        "print(\"\\nTop Bigrams in Non-Suicidal Tweets:\")\n",
        "print(top_bigrams_non_suicidal)\n",
        "\n",
        "# Plot suicidal tweet bigrams\n",
        "if top_bigrams_suicidal:\n",
        "    suicidal_bigram_words = [bigram for bigram, freq in top_bigrams_suicidal]\n",
        "    suicidal_bigram_freqs = [freq for bigram, freq in top_bigrams_suicidal]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))  # Use fig and ax for better control\n",
        "    sns.barplot(x=suicidal_bigram_freqs, y=suicidal_bigram_words, palette='Reds_r', ax=ax)\n",
        "\n",
        "    ax.set_title('Top 20 Bigrams in Suicidal Tweets', fontsize=16, fontweight='bold')\n",
        "    ax.set_xlabel('Frequency', fontsize=14)\n",
        "    ax.set_ylabel('Bigrams', fontsize=14)\n",
        "    ax.tick_params(axis='x', labelsize=12)\n",
        "    ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "    sns.despine(ax=ax)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(bottom=0.2)\n",
        "\n",
        "    # Add figure caption below the plot\n",
        "    fig.text(\n",
        "        0.5, 0.02,\n",
        "        'Figure X - Bhavesh to add after we add other figures to report',\n",
        "        ha='center',\n",
        "        fontsize=12,\n",
        "        fontstyle='italic'\n",
        "    )\n",
        "\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No bigrams found in suicidal tweets.\")\n",
        "\n",
        "# Plot non-suicidal tweet bigrams\n",
        "if top_bigrams_non_suicidal:\n",
        "    non_suicidal_bigram_words = [bigram for bigram, freq in top_bigrams_non_suicidal]\n",
        "    non_suicidal_bigram_freqs = [freq for bigram, freq in top_bigrams_non_suicidal]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    sns.barplot(x=non_suicidal_bigram_freqs, y=non_suicidal_bigram_words, palette='Blues_r', ax=ax)\n",
        "\n",
        "    ax.set_title('Top 20 Bigrams in Non-Suicidal Tweets', fontsize=16, fontweight='bold')\n",
        "    ax.set_xlabel('Frequency', fontsize=14)\n",
        "    ax.set_ylabel('Bigrams', fontsize=14)\n",
        "    ax.tick_params(axis='x', labelsize=12)\n",
        "    ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "    sns.despine(ax=ax)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(bottom=0.2)\n",
        "\n",
        "    # Add figure caption below the plot\n",
        "    fig.text(\n",
        "        0.5, 0.02,\n",
        "        'Figure X - Bhavesh to add after we add other figures to report',\n",
        "        ha='center',\n",
        "        fontsize=12,\n",
        "        fontstyle='italic'\n",
        "    )\n",
        "\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No bigrams found in non-suicidal tweets.\")\n"
      ],
      "metadata": {
        "id": "2lqqQ9t5XotS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bhavesh\n",
        "\n",
        "Thoughts following the above plot:\n",
        "\n",
        "* Bigrams/trigrams might be informative features to use in the model given how different they are across labels\n",
        "* Context is important as bigrams won't pick up on them\n",
        "* Indicates the need to look at sentiment polarity\n"
      ],
      "metadata": {
        "id": "OOn57xe2hogt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reddit_mental_health_data"
      ],
      "metadata": {
        "id": "C_uqVjWkZNke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a frequency plot of the status associated to the tweet\n",
        "sns.countplot(data=reddit_mental_health_data,\n",
        "              y='target',\n",
        "              order=reddit_mental_health_data['target'].value_counts().index\n",
        "            )\n",
        "\n",
        "# Set title\n",
        "plt.title(\"Mental health discorder frequency in reddit_mental_health_data\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xn3kH8xVZNHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create figure and axis for better layout control\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Define the unique number of targets (mental health conditions)\n",
        "unique_targets = reddit_mental_health_data['target'].nunique()\n",
        "\n",
        "# Plot the distribution of mental health conditions by post count\n",
        "sns.countplot(\n",
        "    data=reddit_mental_health_data,\n",
        "    y='target',\n",
        "    order=reddit_mental_health_data['target'].value_counts().index\n",
        "    ax=ax,\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "# Add a descriptive title and axis labels for clarity\n",
        "ax.set_title(\"Frequency of Mental Health Conditions in reddit_mental_health_data\", fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel(\"Number of Posts\", fontsize=14)\n",
        "ax.set_ylabel(\"Mental Health Condition\", fontsize=14)\n",
        "\n",
        "# Adjust tick label sizes to improve readability\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "# Remove top and right spines for a cleaner look\n",
        "sns.despine(ax=ax)\n",
        "\n",
        "# Adjust layout and make space at the bottom for the caption\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(bottom=0.2)\n",
        "\n",
        "# Add figure number and caption below the plot\n",
        "fig.text(\n",
        "    0.5, 0.02,\n",
        "    'Figure 6.3.2',\n",
        "    fontsize=12,\n",
        "    fontstyle='italic',\n",
        "    ha='center'\n",
        ")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3f6rUK1U6O7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate 95th percentile threshold to reduce skew from long outliers\n",
        "percentile_95 = reddit_mental_health_data['text_length'].quantile(0.95)\n",
        "\n",
        "# Filter data below the 95th percentile\n",
        "filtered_data = reddit_mental_health_data[reddit_mental_health_data['text_length'] <= percentile_95]\n",
        "\n",
        "# Calculate summary statistics on filtered data\n",
        "mean_length = filtered_data['text_length'].mean()\n",
        "median_length = filtered_data['text_length'].median()\n",
        "max_length = filtered_data['text_length'].max()\n",
        "min_length = filtered_data['text_length'].min()\n",
        "\n",
        "# Create figure and axis for better layout control\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "# Plot histogram on filtered data\n",
        "sns.histplot(\n",
        "    data=filtered_data,\n",
        "    x='text_length',\n",
        "    bins=50,\n",
        "    kde=True,\n",
        "    color='skyblue',\n",
        "    edgecolor='white',\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# Style the KDE line for better visibility\n",
        "plt.setp(ax.lines, linewidth=2, color='#333F4B')\n",
        "\n",
        "# Add mean and median vertical lines\n",
        "ax.axvline(mean_length, color='#FF5733', linestyle='--', linewidth=2, label=f'Mean: {mean_length:.0f} words')\n",
        "ax.axvline(median_length, color='#28B463', linestyle='-.', linewidth=2, label=f'Median: {median_length:.0f} words')\n",
        "\n",
        "# Add title and axis labels\n",
        "ax.set_title('Distribution of Post Lengths on Reddit (Filtered at 95th Percentile)', fontsize=18, fontweight='bold', pad=15)\n",
        "ax.set_xlabel('Number of Words', fontsize=14, labelpad=10)\n",
        "ax.set_ylabel('Frequency', fontsize=14, labelpad=10)\n",
        "\n",
        "# Configure legend\n",
        "ax.legend(frameon=False, fontsize=12, loc='upper right', bbox_to_anchor=(0.95, 0.95))\n",
        "\n",
        "# Adjust tick label sizes for readability\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "# Remove spines for a cleaner appearance\n",
        "sns.despine(ax=ax)\n",
        "\n",
        "# Add summary stats box inside the figure\n",
        "fig.text(\n",
        "    0.75, 0.5,\n",
        "    f'''\n",
        "Min: {min_length:.0f}\n",
        "Median: {median_length:.0f}\n",
        "Mean: {mean_length:.0f}\n",
        "Max: {max_length:.0f}\n",
        "''',\n",
        "    fontsize=12,\n",
        "    bbox=dict(facecolor='white', edgecolor='gray', boxstyle='round,pad=0.5')\n",
        ")\n",
        "\n",
        "# Adjust layout and leave space at the bottom for a caption\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(bottom=0.2)\n",
        "\n",
        "# Add figure caption below the plot\n",
        "fig.text(\n",
        "    0.5, 0.02,\n",
        "    'Figure 6.3.3',\n",
        "    fontsize=12,\n",
        "    fontstyle='italic',\n",
        "    ha='center'\n",
        ")\n",
        "\n",
        "# Set x axis lower limit\n",
        "plt.xlim(0)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ksMpRPbhhVTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def clean_tokenize_filtered(text):\n",
        "    \"\"\"\n",
        "    Tokenize text, lemmatize, remove stopwords,\n",
        "    and keep only NOUN and ADJ tokens.\n",
        "    \"\"\"\n",
        "    if isinstance(text, str):\n",
        "        doc = nlp(text.lower())\n",
        "        allowed_pos = ['NOUN', 'ADJ']\n",
        "        tokens = [\n",
        "            token.lemma_\n",
        "            for token in doc\n",
        "            if token.is_alpha and not token.is_stop and token.pos_ in allowed_pos\n",
        "        ]\n",
        "        return tokens\n",
        "    return []\n",
        "\n",
        "def get_top_ngrams(texts, ngram_range=2, top_n=20):\n",
        "    \"\"\"\n",
        "    Extract top n-grams from a list of texts after filtering.\n",
        "    \"\"\"\n",
        "    ngram_list = []\n",
        "\n",
        "    for text in texts:\n",
        "        tokens = clean_tokenize_filtered(text)\n",
        "        if len(tokens) >= ngram_range:\n",
        "            ngrams = zip(*[tokens[i:] for i in range(ngram_range)])\n",
        "            ngram_list.extend([' '.join(gram) for gram in ngrams])\n",
        "\n",
        "    ngram_counts = Counter(ngram_list)\n",
        "    return ngram_counts.most_common(top_n)\n",
        "\n",
        "# Iterate through each mental health condition in the dataset\n",
        "unique_conditions = reddit_mental_health_data['target'].unique()\n",
        "\n",
        "# Start figure numbering (optional)\n",
        "figure_num = 1\n",
        "\n",
        "for condition in unique_conditions:\n",
        "    print(f\"\\nTop Bigrams for {condition} Posts (Filtered):\\n\")\n",
        "\n",
        "    # Combine 'text' and 'title' fields for analysis\n",
        "    condition_texts = (\n",
        "        reddit_mental_health_data[reddit_mental_health_data['target'] == condition]['text'] + ' ' +\n",
        "        reddit_mental_health_data[reddit_mental_health_data['target'] == condition]['title']\n",
        "    )\n",
        "\n",
        "    # Get top bigrams for the condition\n",
        "    top_bigrams = get_top_ngrams(condition_texts, ngram_range=2, top_n=10)\n",
        "\n",
        "    # Print bigrams and their frequencies\n",
        "    for bigram, freq in top_bigrams:\n",
        "        print(f\"{bigram}: {freq}\")\n",
        "\n",
        "    # Plot top bigrams if any are found\n",
        "    if top_bigrams:\n",
        "        bigram_phrases = [bigram for bigram, freq in top_bigrams]\n",
        "        bigram_freqs = [freq for bigram, freq in top_bigrams]\n",
        "\n",
        "        # Create figure and axis\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "        # Barplot for bigrams\n",
        "        sns.barplot(x=bigram_freqs, y=bigram_phrases, palette='viridis', ax=ax)\n",
        "\n",
        "        # Titles and labels\n",
        "        ax.set_title(f'Top 10 Filtered Bigrams in {condition} Posts', fontsize=16, fontweight='bold')\n",
        "        ax.set_xlabel('Frequency', fontsize=14)\n",
        "        ax.set_ylabel('Bigrams', fontsize=14)\n",
        "\n",
        "        # Adjust tick label sizes\n",
        "        ax.tick_params(axis='x', labelsize=12)\n",
        "        ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "        sns.despine(ax=ax)\n",
        "\n",
        "        # Adjust layout and reserve space for caption\n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(bottom=0.2)\n",
        "\n",
        "        # Add figure caption below the plot\n",
        "        fig.text(\n",
        "            0.5, 0.02,  # Centered at the bottom\n",
        "            f'Figure {figure_num}: Top bigrams in {condition} posts',\n",
        "            ha='center',\n",
        "            fontsize=12,\n",
        "            fontstyle='italic'\n",
        "        )\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        # Increment figure number for next plot\n",
        "        figure_num += 1\n",
        "\n",
        "    else:\n",
        "        print(f\"No meaningful bigrams found for {condition} posts.\")"
      ],
      "metadata": {
        "id": "1GWDviIrazo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dreaddit"
      ],
      "metadata": {
        "id": "v_Jrz-lJkcvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a frequency plot of the status associated to the tweet\n",
        "sns.countplot(data=dreaddit,\n",
        "              y='label',\n",
        "              order=dreaddit['label'].value_counts().index\n",
        "            )\n",
        "# Set title\n",
        "plt.title(\"Stress label frequency in dreaddit\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z_4tkBYYka-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate label counts for summary stats\n",
        "label_counts = dreaddit['label'].value_counts()\n",
        "\n",
        "# Basic statistics\n",
        "total_labels = len(dreaddit)\n",
        "num_classes = dreaddit['label'].nunique()\n",
        "most_common_label = label_counts.idxmax()\n",
        "most_common_count = label_counts.max()\n",
        "\n",
        "# Create figure and axis for better layout control\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "# Plot the frequency of labels\n",
        "sns.countplot(\n",
        "    data=dreaddit,\n",
        "    y='label',\n",
        "    order=label_counts.index,\n",
        "    palette='Set2',\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# Add title and axis labels\n",
        "ax.set_title('Stress Label Frequency in Dreaddit Dataset', fontsize=18, fontweight='bold', pad=15)\n",
        "ax.set_xlabel('Number of Posts', fontsize=14, labelpad=10)\n",
        "ax.set_ylabel('Label', fontsize=14, labelpad=10)\n",
        "\n",
        "# Adjust tick label sizes for readability\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "# Remove spines for a cleaner appearance\n",
        "sns.despine(ax=ax)\n",
        "\n",
        "# Add summary stats box inside the figure\n",
        "fig.text(\n",
        "    0.7, 0.5,\n",
        "    f'''\n",
        "Total Posts: {total_labels}\n",
        "Unique Labels: {num_classes}\n",
        "Most Common: {most_common_label} ({most_common_count})\n",
        "''',\n",
        "    fontsize=12,\n",
        "    bbox=dict(facecolor='white', edgecolor='gray', boxstyle='round,pad=0.5')\n",
        ")\n",
        "\n",
        "# Adjust layout and leave space at the bottom for a caption\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(bottom=0.2)\n",
        "\n",
        "# Add figure caption below the plot\n",
        "fig.text(\n",
        "    0.5, 0.02,\n",
        "    'Figure 6.4.2',\n",
        "    fontsize=12,\n",
        "    fontstyle='italic',\n",
        "    ha='center'\n",
        ")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aI021ELLHvoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate proportion of stressful posts per subreddit\n",
        "subreddit_stress = (\n",
        "    dreaddit.groupby('subreddit')['label_num']\n",
        "    .mean()\n",
        "    .sort_values(ascending=False)\n",
        ")\n",
        "\n",
        "# Plot proportion of stressful posts by subreddit\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=subreddit_stress.values, y=subreddit_stress.index)\n",
        "plt.title('Proportion of Stressful Posts by Subreddit')\n",
        "plt.xlabel('Proportion of Stressful Posts')\n",
        "plt.ylabel('Subreddit')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lAZaSumqirbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot post text length by stress label\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='label', y='text_length', data=dreaddit)\n",
        "plt.title('Post Text Length by Stress Label')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Text Length (Word Count)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yyYTNdK_m5TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare LIWC emotional features across stress labels\n",
        "liwc_emotion_cols = [\n",
        "    'lex_liwc_negemo', 'lex_liwc_anx', 'lex_liwc_sad',\n",
        "    'lex_liwc_anger', 'lex_liwc_death'\n",
        "]\n",
        "\n",
        "(\n",
        "    dreaddit[liwc_emotion_cols + ['label_num']]\n",
        "    .groupby('label_num')\n",
        "    .mean()\n",
        "    .T\n",
        "    .plot(kind='bar', figsize=(12, 6))\n",
        ")\n",
        "plt.title('Average LIWC Emotional Features by Stress Label')\n",
        "plt.ylabel('Average LIWC Score')\n",
        "plt.xlabel('LIWC Emotional Features')\n",
        "plt.legend(title='Stress Label', labels=['Not Stressful', 'Stressful'])\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iSiTjuSem5Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare DAL features across stress labels\n",
        "dal_cols = [\n",
        "    'lex_dal_avg_pleasantness',\n",
        "    'lex_dal_avg_activation',\n",
        "    'lex_dal_avg_imagery'\n",
        "]\n",
        "\n",
        "(\n",
        "    dreaddit[dal_cols + ['label_num']]\n",
        "    .groupby('label_num')\n",
        "    .mean()\n",
        "    .T\n",
        "    .plot(kind='bar', figsize=(12, 6))\n",
        ")\n",
        "\n",
        "plt.title('Average DAL Features by Stress Label')\n",
        "plt.ylabel('Average DAL Score')\n",
        "plt.xlabel('DAL Features')\n",
        "plt.legend(title='Stress Label', labels=['Not Stressful', 'Stressful'])\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0wrIsKI6m5by"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix for psycholinguistic features (LIWC and DAL)\n",
        "psycholinguistic_cols = liwc_emotion_cols + dal_cols\n",
        "correlation_matrix = dreaddit[psycholinguistic_cols].corr()\n",
        "\n",
        "# Plot correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap of LIWC and DAL Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jikHK72um5gO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gkWknl5WdDYD",
        "0Q1n5wXesBqy",
        "kZHR3cuht3IA",
        "0s82rYlAt549",
        "q0CXgFR4updU",
        "VpPJJSsaxwM5",
        "aAN_2r9bhRuS",
        "I74crXQetB7p",
        "edEf6VjGtRBB",
        "mCZtw1Nktbcx",
        "B8gjDgMRwEo3",
        "ChtET-GC2koR",
        "yKigDcOljQKI",
        "Q9dxuFR4w8ym",
        "YQvN78WXXspv",
        "3X6npzu_YmsO",
        "eUy0WQwKkGez",
        "yo7faL6otVtB",
        "z93LnXnHoviP"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}